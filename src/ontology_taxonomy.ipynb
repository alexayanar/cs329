{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae5479d2d507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    383\u001b[0m   {\n\u001b[1;32m    384\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m    \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Ontology and Taxonomy\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Table of Contents\\n\",\n",
    "    \"\\n\",\n",
    "    \"* [Install WordNet](#Install-WordNet)\\n\",\n",
    "    \"* [Synsets](#Synsets)\\n\",\n",
    "    \"* [Lemmas](#Lemmas)\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Reference\\n\",\n",
    "    \"\\n\",\n",
    "    \"* https://www.nltk.org/howto/wordnet.html\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Install WordNet\\n\",\n",
    "    \"\\n\",\n",
    "    \"Verify the SSL (Secure Sockets Layer) certificate:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 30,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import ssl\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    _create_unverified_https_context = ssl._create_unverified_context\\n\",\n",
    "    \"except AttributeError:\\n\",\n",
    "    \"    pass\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    ssl._create_default_https_context = _create_unverified_https_context\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Install WordNet from [NLTK](https://www.nltk.org)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 31,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[nltk_data] Downloading package wordnet to /Users/jdchoi/nltk_data...\\n\",\n",
    "      \"[nltk_data]   Unzipping corpora/wordnet.zip.\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"True\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 31,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"import nltk\\n\",\n",
    "    \"nltk.download('wordnet')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Synsets\\n\",\n",
    "    \"\\n\",\n",
    "    \"Retrieve all synsets of a word as the list of [Synset](https://www.nltk.org/api/nltk.corpus.reader.html?highlight=synset#nltk.corpus.reader.wordnet.Synset):\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 32,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[Synset('dog.n.01'),\\n\",\n",
    "       \" Synset('frump.n.01'),\\n\",\n",
    "       \" Synset('dog.n.03'),\\n\",\n",
    "       \" Synset('cad.n.01'),\\n\",\n",
    "       \" Synset('frank.n.02'),\\n\",\n",
    "       \" Synset('pawl.n.01'),\\n\",\n",
    "       \" Synset('andiron.n.01'),\\n\",\n",
    "       \" Synset('chase.v.01')]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 32,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"from nltk.corpus import wordnet as wn\\n\",\n",
    "    \"wn.synsets('dog')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"You can specify the part-of-speech (tag) of the word:\\n\",\n",
    "    \"\\n\",\n",
    "    \"* `n`: noun\\n\",\n",
    "    \"* `v`: verb\\n\",\n",
    "    \"* `a`: adjective\\n\",\n",
    "    \"* `r`: adverb\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 49,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[Synset('dog.n.01'),\\n\",\n",
    "       \" Synset('frump.n.01'),\\n\",\n",
    "       \" Synset('dog.n.03'),\\n\",\n",
    "       \" Synset('cad.n.01'),\\n\",\n",
    "       \" Synset('frank.n.02'),\\n\",\n",
    "       \" Synset('pawl.n.01'),\\n\",\n",
    "       \" Synset('andiron.n.01')]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 49,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"dogs = wn.synsets('dog', pos='n')\\n\",\n",
    "    \"dogs\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Retrieve the synset directly from the sense ID:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 46,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"False\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 46,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"dog_0 = wn.synset('dog.n.01')\\n\",\n",
    "    \"\\n\",\n",
    "    \"Synset == dogs[0]\\n\",\n",
    "    \"Synset == dogs[1]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Retrieve the direct hyponyms\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 51,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[Synset('basenji.n.01'),\\n\",\n",
    "       \" Synset('corgi.n.01'),\\n\",\n",
    "       \" Synset('cur.n.01'),\\n\",\n",
    "       \" Synset('dalmatian.n.02'),\\n\",\n",
    "       \" Synset('great_pyrenees.n.01'),\\n\",\n",
    "       \" Synset('griffon.n.02'),\\n\",\n",
    "       \" Synset('hunting_dog.n.01'),\\n\",\n",
    "       \" Synset('lapdog.n.01'),\\n\",\n",
    "       \" Synset('leonberg.n.01'),\\n\",\n",
    "       \" Synset('mexican_hairless.n.01'),\\n\",\n",
    "       \" Synset('newfoundland.n.01'),\\n\",\n",
    "       \" Synset('pooch.n.01'),\\n\",\n",
    "       \" Synset('poodle.n.01'),\\n\",\n",
    "       \" Synset('pug.n.01'),\\n\",\n",
    "       \" Synset('puppy.n.01'),\\n\",\n",
    "       \" Synset('spitz.n.01'),\\n\",\n",
    "       \" Synset('toy_dog.n.01'),\\n\",\n",
    "       \" Synset('working_dog.n.01')]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 51,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"dog_0.hyponyms()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Retreive the direct hypernyms:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 50,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 50,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"dog_0.hypernyms()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Retrieve all indrect hypernyms:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 94,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[[Synset('entity.n.01'),\\n\",\n",
    "       \"  Synset('physical_entity.n.01'),\\n\",\n",
    "       \"  Synset('object.n.01'),\\n\",\n",
    "       \"  Synset('whole.n.02'),\\n\",\n",
    "       \"  Synset('living_thing.n.01'),\\n\",\n",
    "       \"  Synset('organism.n.01'),\\n\",\n",
    "       \"  Synset('animal.n.01'),\\n\",\n",
    "       \"  Synset('chordate.n.01'),\\n\",\n",
    "       \"  Synset('vertebrate.n.01'),\\n\",\n",
    "       \"  Synset('mammal.n.01'),\\n\",\n",
    "       \"  Synset('placental.n.01'),\\n\",\n",
    "       \"  Synset('carnivore.n.01'),\\n\",\n",
    "       \"  Synset('canine.n.02'),\\n\",\n",
    "       \"  Synset('dog.n.01')],\\n\",\n",
    "       \" [Synset('entity.n.01'),\\n\",\n",
    "       \"  Synset('physical_entity.n.01'),\\n\",\n",
    "       \"  Synset('object.n.01'),\\n\",\n",
    "       \"  Synset('whole.n.02'),\\n\",\n",
    "       \"  Synset('living_thing.n.01'),\\n\",\n",
    "       \"  Synset('organism.n.01'),\\n\",\n",
    "       \"  Synset('animal.n.01'),\\n\",\n",
    "       \"  Synset('domestic_animal.n.01'),\\n\",\n",
    "       \"  Synset('dog.n.01')]]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 94,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"dog_0.hypernym_paths()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Lemmas\\n\",\n",
    "    \"\\n\",\n",
    "    \"Retrieve all [Lemmas](https://www.nltk.org/api/nltk.corpus.reader.html?highlight=lemma#nltk.corpus.reader.wordnet.Lemma) (synonyms) of the Synset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 61,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[Lemma('dog.n.01.dog'),\\n\",\n",
    "       \" Lemma('dog.n.01.domestic_dog'),\\n\",\n",
    "       \" Lemma('dog.n.01.Canis_familiaris')]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 61,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"dog_0_lemmas = dog_0.lemmas()\\n\",\n",
    "    \"dog_0_lemmas\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Retrieve only the names:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 63,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"dog\\n\",\n",
    "      \"domestic_dog\\n\",\n",
    "      \"Canis_familiaris\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"for l in dog_0_lemmas:\\n\",\n",
    "    \"    print(l.name())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Retrieve the lemma directly from the sense ID:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 71,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"dog_0_lemma = wn.lemma('dog.n.01.dog')\\n\",\n",
    "    \"l = dog_0_lemma\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Retrieve the frequency of the lemma:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 73,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"dog 42\\n\",\n",
    "      \"domestic_dog 0\\n\",\n",
    "      \"Canis_familiaris 0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"for l in dog_0.lemmas():\\n\",\n",
    "    \"    print(l.name(), l.count())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Exercise\\n\",\n",
    "    \"\\n\",\n",
    "    \"Write a function that takes a word and an optional POS tag, and returns the set of all synonyms of the word:\\n\",\n",
    "    \"\\n\",\n",
    "    \"```python\\n\",\n",
    "    \"def synonyms(word: str, pos: Optional[str]=None, count: Optional[int]=0) -> Set[str]:\\n\",\n",
    "    \"    # To be filled\\n\",\n",
    "    \"```\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 76,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from typing import Set, Optional\\n\",\n",
    "    \"\\n\",\n",
    "    \"def synonyms(word: str, pos: Optional[str]=None, count: Optional[int]=0) -> Set[str]:\\n\",\n",
    "    \"    syns = set()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for synset in wn.synsets(word, pos):\\n\",\n",
    "    \"        for lemma in synset.lemmas():\\n\",\n",
    "    \"            if lemma.count() >= count:\\n\",\n",
    "    \"                syns.add(lemma.name())\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return syns\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 78,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{'Canis_familiaris',\\n\",\n",
    "       \" 'andiron',\\n\",\n",
    "       \" 'blackguard',\\n\",\n",
    "       \" 'bounder',\\n\",\n",
    "       \" 'cad',\\n\",\n",
    "       \" 'click',\\n\",\n",
    "       \" 'detent',\\n\",\n",
    "       \" 'dog',\\n\",\n",
    "       \" 'dog-iron',\\n\",\n",
    "       \" 'domestic_dog',\\n\",\n",
    "       \" 'firedog',\\n\",\n",
    "       \" 'frank',\\n\",\n",
    "       \" 'frankfurter',\\n\",\n",
    "       \" 'frump',\\n\",\n",
    "       \" 'heel',\\n\",\n",
    "       \" 'hot_dog',\\n\",\n",
    "       \" 'hotdog',\\n\",\n",
    "       \" 'hound',\\n\",\n",
    "       \" 'pawl',\\n\",\n",
    "       \" 'weenie',\\n\",\n",
    "       \" 'wiener',\\n\",\n",
    "       \" 'wienerwurst'}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 78,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"synonyms('dog', 'n')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 79,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{'dog', 'hound'}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 79,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"synonyms('dog', 'n', 1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 80,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{'chase', 'dog', 'go_after', 'hound', 'track', 'trail'}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 80,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"synonyms('dog', count=1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"You can also rerieve antonyms of the lemma:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 86,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"buy [Lemma('sell.v.01.sell')]\\n\",\n",
    "      \"purchase []\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"buy = wn.synset('buy.v.01')\\n\",\n",
    "    \"for l in buy.lemmas():\\n\",\n",
    "    \"    print(l.name(), l.antonyms())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Lowest Common Hypernyms\\n\",\n",
    "    \"\\n\",\n",
    "    \"NLTK already provides a method to find the lowest common hypernyms:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 89,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"[Synset('carnivore.n.01')]\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 89,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"dog = wn.synset('dog.n.01')\\n\",\n",
    "    \"cat = wn.synset('cat.n.01')\\n\",\n",
    "    \"dog.lowest_common_hypernyms(cat)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"NLTK also provides methods to measure the similarty between two senses:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 92,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"0.2\\n\",\n",
    "      \"2.0281482472922856\\n\",\n",
    "      \"0.8571428571428571\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print(dog.path_similarity(cat))\\n\",\n",
    "    \"print(dog.lch_similarity(cat))\\n\",\n",
    "    \"print(dog.wup_similarity(cat))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Exercise\\n\",\n",
    "    \"\\n\",\n",
    "    \"Write a function that takes two sense IDs, finds the lowest common hypernyms, and returns the path from each lowest common hypernym to its root:\\n\",\n",
    "    \"\\n\",\n",
    "    \"```python\\n\",\n",
    "    \"def lch_paths(sense_0: str, sense_1: str) -> List[List[Synset]]:\\n\",\n",
    "    \"    # To be filled\\n\",\n",
    "    \"```\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 103,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from nltk.corpus.reader import Synset\\n\",\n",
    "    \"\\n\",\n",
    "    \"def lch_paths(sense_0: str, sense_1: str) -> List[List[Synset]]:\\n\",\n",
    "    \"    synset_0 = wn.synset(sense_0)\\n\",\n",
    "    \"    synset_1 = wn.synset(sense_1)\\n\",\n",
    "    \"    hypernym_paths_0 = synset_0.hypernym_paths()\\n\",\n",
    "    \"    lch = synset_0.lowest_common_hypernyms(synset_1)\\n\",\n",
    "    \"    paths = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for hypernym in lch:\\n\",\n",
    "    \"        for syn_list in hypernym_paths_0:\\n\",\n",
    "    \"            i = next((i for i, syn in enumerate(syn_list) if syn == hypernym), -1)\\n\",\n",
    "    \"            if i >= 0: paths.append(syn_list[:i+1])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return paths\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 104,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"entity.n.01 -> physical_entity.n.01 -> object.n.01 -> whole.n.02 -> living_thing.n.01 -> organism.n.01 -> animal.n.01 -> chordate.n.01 -> vertebrate.n.01 -> mammal.n.01 -> placental.n.01 -> carnivore.n.01\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"paths = lch_paths('dog.n.01', 'cat.n.01')\\n\",\n",
    "    \"for path in paths:\\n\",\n",
    "    \"    print(' -> '.join([syn.name() for syn in path]))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.7.4\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
